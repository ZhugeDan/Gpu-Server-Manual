没问题！看到你这么有干劲，我也热血沸腾了！😤

既然今天下午是“决战时刻”，为了不让你在翻以前的对话记录时手忙脚乱，我把之前所有碎片化的建议，整理成了一份**《从零开始搭建实验室 GPU 服务器作战清单》**。

请把这段话截图或保存，严格按照这个顺序执行。

------

### ⚔️ 第一阶段：重装系统（物理接触）

**目标：** 把旧的 CentOS 抹掉，换成纯净的 Ubuntu Server，并确保 SSH 服务就绪。

1. **准备硬件：**
   - 插好制作好的 **Ubuntu Server 22.04 U 盘**（插机箱背面蓝色口）。
   - 插好 **网线**（连接你的笔记本和服务器 `eno1` 口）。
   - 接好 **显示器** 和 **键盘**。
2. **进入安装：**
   - 开机狂按 **`F11`** (或 `F12`)，选择 `UEFI: [U盘名]` 启动。
   - 选择 `Try or Install Ubuntu Server`。
3. **关键设置（避坑点）：**
   - **网络：** 看到 IP 不用管，也不要设静态，直接 `Done` 跳过。
   - **源/代理：** 留空，报错就选 `Continue without updating`，**离线安装**。
   - **硬盘分区（最重要）：**
     - 选 **`Use an entire disk`**（使用整块磁盘）。
     - **取消勾选** `Set up this disk as an LVM group`（推荐小白直接裸盘）。
     - 确认选中 Samsung 990 PRO 2TB。
   - **SSH（生死攸关）：**
     - **必须勾选** `[x] Install OpenSSH server`。
4. **结束：**
   - 安装完点击 `Reboot Now`。
   - 屏幕黑掉提示拔盘时，**立刻拔掉 U 盘**，回车。

------

### 🔌 第二阶段：打通网络（构建“二人世界”）

**目标：** 让服务器通过你的笔记本上网，并建立 SSH 连接。

1. **笔记本设置（Windows）：**
   - 连上 Wi-Fi（确保能上网）。
   - `控制面板` -> `网络连接` -> 右键 Wi-Fi -> `属性` -> `共享`。
   - 勾选 **“允许其他网络用户...”**，家庭网络连接选 **“以太网”**（插网线的那个口）。
2. **服务器端操作（登录进系统后）：**
   - 输入 `ip addr`。
   - 查看 `eno1` 是否获取到了 `192.168.137.x` 网段的 IP。
   - 测试：`ping baidu.com`。如果通了，恭喜你，最难的一关过了！
3. **丢掉键盘：**
   - 回到笔记本，打开 CMD 或 PowerShell。
   - 输入：`ssh 用户名@服务器IP`。
   - **成功登录后，之后所有操作都在笔记本上复制粘贴完成！**

------

### 🛠️ 第三阶段：环境配置（复制粘贴）

**目标：** 换源加速，安装显卡驱动。

1. **换国内源（哈工大/阿里）：**

   - 参考教程 1，编辑 `/etc/apt/sources.list`，把里面的地址全换成国内镜像（如 `mirrors.aliyun.com`），否则下载速度会慢到让你怀疑人生。

     

     

   - 运行 `sudo apt update && sudo apt upgrade -y`。

2. **装显卡驱动（推荐稳健法）：**

   - 不要用教程里的 `.run` 文件编译法 2。

     

     

   - 直接运行：`sudo apt install nvidia-driver-535-server utils`。

   - 装完输入 `sudo reboot` 重启。

   - 重启连上后，输入 `nvidia-smi`。看到表格和 3 张显卡，就算胜利。

------

### 🏗️ 第四阶段：LXD 初始化（魔改教程）

**目标：** 部署虚拟化环境，分配存储池。

1. **安装 LXD：**
   - `sudo snap install lxd`
2. **初始化（重点修改）：**
   - 运行 `sudo lxd init`。
   - **一路回车选默认，除了下面这一步：**
   - 当问到 `Create a new ZFS pool?` -> **Yes**。
   - `Would you like to use an existing block device?` -> **No** (教程里选的是 No，但我们这里一定要注意，我们是用 Loop 文件模式)。
   - **Size in GB:** 输入 **`1500`** (给 LXD 分 1.5TB，留 500G 给宿主机，防止爆盘)。
3. **网络网桥：**
   - 如果不想折腾复杂的物理桥接，`lxd init` 里的网络部分直接一路回车（使用默认的 `lxdbr0`）。

------

### 🚀 第五阶段：分发与远程（未来展望）

**目标：** 创建第一个容器，并实现从宿舍访问。

1. **创建容器：**
   - `lxc launch ubuntu:22.04 my-first-container`
2. **分配显卡：**
   - `lxc config device add my-first-container gpu0 gpu id=0` (把第0张卡分给它)。
3. **内网穿透（回家也能连）：**
   - 去 **Tailscale** 官网注册账号。
   - 在宿主机安装 Tailscale：`curl -fsSL https://tailscale.com/install.sh | sh`。
   - 按提示显示的链接登录一下。
   - 以后你在宿舍，只要电脑也开着 Tailscale，就能直接 SSH 连回来了！

------

### 💡 给你的最后锦囊

- **遇到报错不要慌：** 此时你已经有网了，直接把报错复制给 AI 问，或者拍照发给我。
- **关于教程 PDF：** 那份教程现在主要用来**参考概念**（比如怎么换源，怎么创建容器），**不要**照抄它的分区命令和网络配置命令。
- **心态：** 重装系统是计算机人的基本功，把它当成一次升级打怪的游戏。

祝你今天下午大获全胜！拿到 `nvidia-smi` 那个画面的瞬间，你会觉得一切都值了！加油！🔥







这真是太令人激动了！看着你从 `NO-CARRIER` 一路过关斩将，到现在成功创建了容器 `smiling-cougar`（微笑的美洲狮，系统随机起的名字，很吉利！），并且显卡驱动也完美工作。

既然你已经决定抛弃那份过时的 PDF 教程，那我就做你的**“首席架构师”**。

针对你们实验室 **“不到10人、3张显卡、需要在一间办公室使用”** 的需求，我为你设计了一套最现代化、维护成本最低的**“流水线方案”**。

请严格按照以下 **5 个步骤** 操作。建议你拿出小本本（或者截图）记下来，这就是你以后的**“管理员手册”**。

------

### 🟢 第一步：打造完美的“样板房”（Template）

目前的 `smiling-cougar` 只是一个毛坯房。我们需要把它装修好（装好通用软件），以后所有同学的容器都以它为蓝本复制，这样大家就不用重复装 Python、CUDA 了。

1. 进入容器

在 PowerShell 输入：

Bash

```
lxc exec smiling-cougar bash
```

*(你现在的身份变成了 `root@smiling-cougar`，代表你在容器里了)*

2. 装修容器（安装基础软件）

在容器里依次执行：

Bash

```
# 更新软件源
apt update && apt upgrade -y

# 安装必备工具 (根据你们组需求加，比如 git, vim, wget, curl)
apt install -y git vim wget curl build-essential

# 安装显卡支持工具 (关键！否则容器里用不了 nvidia-smi)
# 注意：这里只装工具，不装驱动核心，因为是共享宿主机的
apt install -y nvidia-utils-535-server
```

3. 验证显卡

在容器里输入：

Bash

```
nvidia-smi
```

- **成功标准：** 必须能看到 3 张显卡的列表（和宿主机看到的一样）。
- *如果这一步报错，请告诉我，我们微调一下。如果不报错，继续。*
- 退出并保存为镜像

装修好了，我们要把它“封存”起来做成模板。

Bash

```
# 退出容器
exit

# 把 smiling-cougar 停止
lxc stop smiling-cougar

# 把它打包成一个叫 "lab-base" 的镜像
lxc publish smiling-cougar --alias lab-base
```

*(这一步可能要几分钟，完成后 `lab-base` 就是你们实验室的**黄金母盘**了)*

------

### 🔵 第二步：为同学创建容器（以“张三”为例）

假设来了个新同学叫 **张三 (zhangsan)**。

**1. 从模板创建容器**

Bash

```
lxc init lab-base zhangsan
```

*(注意用 `init` 而不是 `launch`，因为我们还要改配置再开机)*

2. 分配显卡

你可以选择给他 全部显卡（推荐，适合小团队互信），或者 指定某一张。

- **方案 A：给全部 3 张卡（简单，推荐）**

  Bash

  ```
  lxc config device add zhangsan gpu gpu
  ```

- **方案 B：只给第 0 张卡（防抢占）**

  Bash

  ```
  lxc config device add zhangsan gpu0 gpu id=0
  ```

**3. 设置开机自启 (可选)**

Bash

```
lxc config set zhangsan boot.autostart true
```

------

### 🟠 第三步：配置网络端口（核心！）

因为你们用的是 NAT 网络（容器 IP 外界连不上），我们需要在宿主机上开个“后门”给张三。

**规则设计：**

- 宿主机 IP：`192.168.137.4`
- 张三的 SSH 端口：`10001`
- 李四的 SSH 端口：`10002`
- ...以此类推

**给张三做端口映射：**

Bash

```
lxc config device add zhangsan ssh-proxy proxy listen=tcp:0.0.0.0:10001 connect=tcp:127.0.0.1:22
```

*(这句话的意思是：谁访问服务器的 10001 端口，我就把他转给张三的 22 端口)*

------

### 🟣 第四步：设置用户名和密码（交付）

现在启动容器，进去给张三建个账号。

**1. 启动容器**

Bash

```
lxc start zhangsan
```

**2. 进去建号**

Bash

```
lxc exec zhangsan bash
```

**3. 在容器里操作：**

Bash

```
# 创建用户 zhangsan 并自动创建家目录 (-m) 和指定 bash (-s)



# 给 zhangsan 设置密码 (会让你输两次)
passwd zhangsan

# 给 zhangsan 管理员权限 (sudo) - 可选，为了方便建议给
usermod -aG sudo zhangsan

# 退出容器
exit
```

------

### 🟡 第五步：通知张三（最终交付）

现在，你可以把下面的信息发给张三了：

> **🎓 实验室服务器连接信息**
>
> - **主机 IP：** `192.168.137.4` (如果以后插回学校网线，换成学校分配的 IP 即可)
> - **端口：** `10001`
> - **用户名：** `zhangsan`
> - **密码：** (你刚才设的)
>
> 💻 连接命令：
>
> ssh zhangsan@192.168.137.4 -p 10001

------

### 📝 总结：如果有 10 个同学怎么做？

你只需要重复 **步骤 2、3、4** 即可。

为了防止你乱，建议你维护一个简单的 Excel 表格：

| **姓名** | **容器名** | **宿主机端口** | **分配显卡** |
| -------- | ---------- | -------------- | ------------ |
| 模板     | lab-base   | -              | -            |
| 张三     | zhangsan   | 10001          | All          |
| 李四     | lisi       | 10002          | All          |
| 王五     | wangwu     | 10003          | GPU 0        |

**现在，先去执行第一步，把那个 `smiling-cougar` 装修好变成模板吧！**





太棒了！你的“始祖巨人” (founding-titan) 已经诞生，这意味着你已经完成了 99% 的基建工作！

针对你现在的 **3 个核心问题**（镜像大小、显卡分配、跑通 MNIST），我来为你提供最终的**实操指南**。

------

### 1️⃣ 这个实例有多大？

因为我们选的是 Miniconda 而不是臃肿的 Anaconda，你的镜像应该非常精简。

查看命令：

在宿主机输入：

Bash

```
lxc image list
```

- **预期结果：** 你会看到 `founding-titan` 的大小大概在 **1.5GB ~ 3GB** 之间。
- **对比：** 如果是 Anaconda 加一堆乱七八糟的库，通常会超过 10GB。这节省下来的空间，足够你多存好几个数据集了！

------

### 2️⃣ 如何分配显卡？给不同学生创建容器？

你有 **3 张 RTX 3090**，对于不到 10 个人的实验室，我有 **两种分配策略** 供你选择。

#### 策略 A：共产主义模式（强烈推荐）

做法： 把 3 张卡都分给每一个学生。

优点： 灵活性最高。因为显卡通常不会 24 小时满载，张三训练的时候李四可能在写代码。大家可以商量着来，“此时此刻谁需要算力谁就用”。

缺点： 可能会有抢占资源的情况（需要口头协调）。

#### 策略 B：包产到户模式

做法： 张三只用卡 0，李四只用卡 1。

优点： 互不干扰。

缺点： 资源浪费。如果张三没任务，卡 0 就闲置了，而李四可能不够用。

------

### 🛠️ 实操演示：给“张三”创建容器 (采用策略 A)

假设我们要给第一个学生 **张三 (zhangsan)** 开号：

**第一步：从“始祖巨人”复制躯体**

Bash

```
lxc init founding-titan zhangsan
```

**第二步：分配显卡 (策略 A - 全给)**

Bash

```
lxc config device add zhangsan gpu gpu
```

*(如果想用策略 B 只给第 0 张卡，命令是：`lxc config device add zhangsan gpu0 gpu id=0`)*

第三步：配置 SSH 端口映射 (关键！)

我们规定：张三用 10001，李四用 10002，以此类推。

Bash

```
lxc config device add zhangsan ssh-proxy proxy listen=tcp:0.0.0.0:10001 connect=tcp:127.0.0.1:22
```

第四步：限制资源 (可选，防止一人撑爆服务器)

比如限制内存 64GB，CPU 16核：

Bash

```
lxc config set zhangsan limits.memory 64GB
lxc config set zhangsan limits.cpu 16
```

**第五步：开机并设密码**

Bash

```
lxc start zhangsan
lxc exec zhangsan bash

# 进去后：
useradd -m -s /bin/bash zhangsan  # 建用户
passwd zhangsan                   # 设密码 (比如 123456)
usermod -aG sudo zhangsan         # 给管理员权限
```

------

### 3️⃣ 终极验证：跑一个手写数字识别 (MNIST)

现在我们就在 **张三** 的容器里，从零配置环境并跑通代码，证明这套系统是完美的。

**请进入张三的容器（如果你刚才退出了）：**

Bash

```
lxc exec zhangsan bash
```

*(注意：以下操作模拟张三视角，完全可以在 `zhangsan` 用户下操作，也可以用 root)*

#### Step 1: 激活 Conda 并创建环境

因为我们有“始祖巨人”的加持，Conda 是现成的！

Bash

```
# 1. 创建一个叫 pytorch_env 的环境，用 Python 3.9
conda create -n pytorch_env python=3.9 -y

# 2. 激活环境
source activate pytorch_env
```

*(注意：在 shell 脚本里用 `source activate` 比 `conda activate` 更稳)*

#### Step 2: 安装 PyTorch

我们用清华源加速安装（或者直接 pip，因为有阿里源加持也很块）：

Bash

```
pip install torch torchvision torchaudio
```

#### Step 3: 编写验证代码 (mnist_test.py)

我为你写好了一个只有 50 行的脚本，它会检测显卡、下载 MNIST 数据集并训练一轮。

**直接复制下面整块代码，粘贴进命令行：**

Bash

```
cat <<EOF > mnist_test.py
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
import time

# 1. 检查显卡
print("-" * 50)
print(f"CUDA Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU Count: {torch.cuda.device_count()}")
    print(f"Current GPU: {torch.cuda.get_device_name(0)}")
else:
    print("❌ Error: GPU not found!")
    exit()
print("-" * 50)

# 2. 准备简单的网络和数据
device = torch.device("cuda")
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])

print("⬇️  Downloading MNIST dataset (might take a minute)...")
train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(28*28, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = torch.flatten(x, 1)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

model = Net().to(device)
optimizer = optim.Adadelta(model.parameters(), lr=1.0)
criterion = nn.CrossEntropyLoss()

# 3. 开始训练 (只跑 100 个 batch 验证速度)
print("🚀 Start Training...")
model.train()
start_time = time.time()

for batch_idx, (data, target) in enumerate(train_loader):
    data, target = data.to(device), target.to(device)
    optimizer.zero_grad()
    output = model(data)
    loss = criterion(output, target)
    loss.backward()
    optimizer.step()
    
    if batch_idx % 10 == 0:
        print(f'Train Batch: {batch_idx}\tLoss: {loss.item():.6f}')
    
    if batch_idx > 50: # 跑 50 个 batch 就停，证明能跑就行
        break

print("-" * 50)
print("✅ Success! PyTorch is running on RTX 3090!")
print("-" * 50)
EOF
```

#### Step 4: 运行！

Bash

```
python mnist_test.py
```

------

### 🎯 预期结果

如果你看到屏幕上出现：

1. `CUDA Available: True`
2. `Current GPU: NVIDIA GeForce RTX 3090`
3. `Train Batch: 0 ... Loss: ...`
4. 最后显示 **`✅ Success!`**

**那么，恭喜你！你的实验室服务器搭建任务圆满完成！🎉**

你可以把 `ssh zhangsan@192.168.137.203 -p 10001` 发给同学了！